[
  {
    "level": 1,
    "description": "A system that can likely thwart amateur attempts (OC1). This includes the operations of many hobbyist hackers, as well as more experienced hackers who implement completely untargeted \"spray and pray\" attacks.",
    "categories": [
      {
        "name": "Weight Security",
        "subcategories": [
          {
            "name": "Weight Storage",
            "controls": [
              {
                "name": "Sensitive data remain internal.",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://www.fierce-network.com/cloud/model-weights-are-heart-ais-intelligence-and-its-achilles-heel",
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has implemented multi-layered security controls for model weights including multi-party access approvals, private-linked storage, egress controls, and detection systems. They explicitly state that model weights are not distributed outside OpenAI and Microsoft, and remain controlled through API access."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/research/confidential-inference-trusted-vms",
                      "https://www.techrepublic.com/article/news-anthropic-ai-safety-level-3/",
                      "https://venturebeat.com/ai/why-anthropic-and-openai-are-obsessed-with-securing-llm-model-weights/"
                    ],
                    "justification": "Anthropic has implemented ASL-3 security standards with over 100 security controls, increased internal security measures to prevent model weight theft, and restricted outbound network traffic. Their CISO dedicates ~50% of time to protecting model weights, demonstrating strong commitment to keeping sensitive data internal."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/blog/products/identity-security/introducing-ai-protection-security-for-the-ai-era",
                      "https://support.google.com/a/answer/15706919?hl=en",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/"
                    ],
                    "justification": "Google has published security frameworks (SAIF) and general privacy commitments, but lacks specific public documentation about internal access controls for AI model weights. While they emphasize data protection and security, there's no clear evidence of implementing RAND's specific recommendations like centralizing weights storage or limiting personnel access."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/legal/faq",
                      "https://x.ai/security",
                      "https://x.ai/legal/privacy-policy"
                    ],
                    "justification": "xAI has published general security measures and data protection policies, but no specific public information addresses internal containment of sensitive data like AI model weights, focusing instead on user data privacy and general security practices."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [
                      "https://www.cio.com/article/3599448/meta-offers-llama-ai-to-us-government-for-national-security.html",
                      "https://en.wikipedia.org/wiki/Llama_(language_model)",
                      "https://finance.yahoo.com/news/llama-copyright-drama-meta-stops-205006551.html"
                    ],
                    "justification": "Meta openly releases Llama model weights to the public under permissive licenses, directly contradicting the requirement that sensitive data remain internal. The company has shifted from case-by-case access (Llama 1) to broad public availability (Llama 2 and later)."
                  }
                }
              },
              {
                "name": "Weight encryption (best effort)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding OpenAI's encryption practices for their AI model weights, despite general encryption policies for customer data."
                  },
                  "Anthropic": {
                    "score": 50,
                    "sources": [
                      "https://venturebeat.com/ai/why-anthropic-and-openai-are-obsessed-with-securing-llm-model-weights/",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/research/confidential-inference-trusted-vms"
                    ],
                    "justification": "Anthropic has publicly disclosed implementing encrypted storage for model weights and confidential computing approaches, but has not specifically confirmed implementation of the 'best effort' weight encryption expected for Security Level 1 as defined in the RAND report."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/docs/security/encryption/default-encryption",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/"
                    ],
                    "justification": "Google has strong general encryption practices (AES-256 for data at rest) and is developing advanced security frameworks (SAIF, Frontier Safety Framework), but there is no specific public evidence of implementing weight encryption as a best-effort measure for AI models as described in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 50,
                    "sources": [
                      "https://guptadeepak.com/the-comprehensive-guide-to-understanding-grok-ai-architecture-applications-and-implications/",
                      "https://x.ai/news/grok-os",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html"
                    ],
                    "justification": "xAI mentions general encryption practices (data in transit and at rest) for Grok, and released Grok-1 weights publicly under Apache 2.0 license. However, no specific public information found about weight encryption as a dedicated security control matching RAND's Security Level 1 requirements."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
                      "https://en.wikipedia.org/wiki/Llama_(language_model)",
                      "https://github.com/meta-llama/llama-models"
                    ],
                    "justification": "No specific public information found regarding Meta's implementation of weight encryption for their AI model weights. While Meta releases model weights openly for many Llama models and mentions various security safeguards, there is no evidence of encryption practices for model weights as described in the RAND report."
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Data centers of cloud providers",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://venturebeat.com/ai/why-anthropic-and-openai-are-obsessed-with-securing-llm-model-weights/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://openai.com/enterprise-privacy"
                    ],
                    "justification": "OpenAI demonstrates strong compliance through multi-layered security controls including Azure-based infrastructure with defense-in-depth approach, multi-party authorization for weight access, private-linked storage resources, egress controls, and encryption (AES-256 at rest, TLS 1.2+ in transit). The organization explicitly states model weights are not distributed outside OpenAI and Microsoft, and implements comprehensive monitoring and access controls."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://www.anthropic.com/news/anthropic-amazon",
                      "https://www.aboutamazon.com/news/aws/amazon-invests-additional-4-billion-anthropic-ai",
                      "https://www.anthropic.com/news/anthropic-amazon-trainium",
                      "https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers"
                    ],
                    "justification": "Anthropic demonstrates strong cloud security practices through partnerships with AWS and Google Cloud, utilizing their enterprise-grade security infrastructure including AWS GovCloud and classified environments. The company employs AWS's multi-layer security features and operates in secure cloud environments, meeting most Security Level 1 requirements for protecting against amateur threats."
                  },
                  "Google": {
                    "score": 75,
                    "sources": [
                      "https://cloud.google.com/docs/security/physical-to-logical-space",
                      "https://cloud.google.com/blog/products/identity-security/introducing-ai-protection-security-for-the-ai-era",
                      "https://www.google.com/about/datacenters/data-security/",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/docs/security/overview/whitepaper"
                    ],
                    "justification": "Google demonstrates comprehensive data center security with 6-layer physical security, encryption at rest, access controls, and their Secure AI Framework (SAIF). While not explicitly addressing RAND Security Level 1 requirements for AI model weights, their infrastructure provides strong foundational security controls."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security",
                      "https://dgtlinfra.com/elon-musk-data-centers/"
                    ],
                    "justification": "xAI uses AWS cloud services as part of their infrastructure and has cloud-first architectures, but there's no specific public information about their compliance with RAND's Security Level 1 requirements for AI model weights security in cloud provider data centers."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://www.edgeless.systems/solutions/ai-model-protection",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://www.maginative.com/article/meta-opens-llama-ai-model-to-us-military-defense-contractors/"
                    ],
                    "justification": "Meta has indicated AI infrastructure investments and partnerships with cloud providers (AWS and Azure hosting Llama models), but no specific public information was found detailing security measures for model weights in cloud provider data centers as expected for RAND Security Level 1."
                  }
                }
              }
            ]
          },
          {
            "name": "Access Control",
            "controls": [
              {
                "name": "Access control for sensitive assets",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://siliconangle.com/2024/04/23/openai-enhances-security-control-cost-management-enterprise-api-users/"
                    ],
                    "justification": "OpenAI has implemented multi-layered access controls for model weights including multi-party approvals, role-based access control (RBAC), private-linked storage with authentication, and an AccessManager Service requiring least-privilege authorization, demonstrating substantial compliance with access control requirements for sensitive assets."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/frontier-model-security",
                      "https://www.anthropic.com/rsp-updates"
                    ],
                    "justification": "Anthropic has implemented multi-party authorization controls requiring two-party approval and time-bounded access for model weights, along with egress bandwidth controls and enhanced security measures under their ASL-3 standards, demonstrating strong access control practices for securing AI model weights."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/",
                      "https://www.lesswrong.com/posts/y8eQjQaCamqdc842k/deepmind-s-frontier-safety-framework-is-weak-and-unambitious",
                      "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/"
                    ],
                    "justification": "Google has published frameworks (SAIF, Frontier Safety Framework) acknowledging the importance of access control for model weights and outlined future plans for implementation, but admits current practices are at 'level 0 out of 4' for security levels, with hundreds having read access to weights without proper controls to prevent copying."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://x.ai/security",
                      "https://en.wikipedia.org/wiki/Grok_(chatbot)"
                    ],
                    "justification": "While xAI demonstrates some security practices like least privilege and IAM controls, they openly released Grok-1's weights publicly, which contradicts RAND's core recommendation to centralize and strictly control access to model weights."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [
                      "https://www.pivotpointsecurity.com/leaking-metas-llama-ai-the-good-the-bad-and-the-very-bad/",
                      "https://github.com/meta-llama/llama-models",
                      "https://en.wikipedia.org/wiki/Llama_(language_model)",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://www.oracle.com/artificial-intelligence/ai-open-weights-models/"
                    ],
                    "justification": "Meta takes an open-source approach with Llama models, making weights publicly available for download, which is fundamentally incompatible with access control requirements for protecting AI model weights as sensitive assets per RAND's Security Level 1 framework."
                  }
                }
              },
              {
                "name": "Access log or audit trail",
                "compliance": {
                  "OpenAI": {
                    "score": 25,
                    "sources": [
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://trust.openai.com/"
                    ],
                    "justification": "OpenAI has mentioned general security measures including access controls and monitoring for model weights protection, but lacks publicly disclosed specific details about access log or audit trail implementation for model weights security."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/transparency/voluntary-commitments",
                      "https://support.anthropic.com/en/articles/9970975-how-to-access-audit-logs",
                      "https://www.anthropic.com/enterprise",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates"
                    ],
                    "justification": "Anthropic demonstrates substantial compliance through ASL-3 security measures including multi-party authorization, hardware authentication, and temporary access controls for model weights. The company specifically mentions audit logs as an enterprise security feature and has implemented access controls with justification requirements and employee approval processes for model weight access."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/vertex-ai/generative-ai/docs/enable-audit-logs",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/",
                      "https://cloud.google.com/vertex-ai/docs/general/audit-logging"
                    ],
                    "justification": "Google has comprehensive audit logging infrastructure (Cloud Audit Logs, Vertex AI audit logs) and mentions AI security frameworks (SAIF), but no specific public documentation was found explicitly addressing audit trails for AI model weights access as required by RAND Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security"
                    ],
                    "justification": "xAI provides a 90-day audit trail for Business Tier accounts with on-demand export capability, demonstrating partial implementation of access logging controls. However, publicly available information is limited regarding comprehensive audit trail practices for AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of access logs or audit trails for AI model weights security as outlined in the RAND report."
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security of Network and Other (Nonweight) Sensitive Assets",
        "subcategories": [
          {
            "name": "Software",
            "controls": [
              {
                "name": "Moderately frequent software update management and compliance monitoring",
                "compliance": {
                  "OpenAI": {
                    "score": 25,
                    "sources": [
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://openai.com/enterprise-privacy"
                    ],
                    "justification": "OpenAI demonstrates some practices related to security updates and monitoring, including bug bounty programs, security audits, and iterative risk assessment updates, but lacks specific public documentation about moderately frequent software update management for model weights security."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy"
                    ],
                    "justification": "Anthropic demonstrates strong compliance through their ASL-3 security measures including comprehensive software inventory management, automated scanning, vulnerability monitoring, endpoint patching processes, and regular safeguard assessments as part of their Responsible Scaling Policy implementation."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/compute/docs/os-patch-management",
                      "https://cloud.google.com/blog/products/identity-security/introducing-ai-protection-security-for-the-ai-era",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/kubernetes-engine/enterprise/docs/concepts/security-patching"
                    ],
                    "justification": "Google has established AI security frameworks (SAIF) and general patch management capabilities for cloud infrastructure, but lacks specific publicly documented policies for moderately frequent updates targeting AI model weights security as described in Security Level 1 of the RAND report."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security",
                      "https://guptadeepak.com/the-comprehensive-guide-to-understanding-grok-ai-architecture-applications-and-implications/",
                      "https://x.ai/legal/privacy-policy"
                    ],
                    "justification": "While xAI has demonstrated some security measures including continuous monitoring, encryption, and security audits, there is no specific public information about their software update management frequency or compliance monitoring procedures related to AI model weights security."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://www.infosecurity-magazine.com/news/meta-new-advances-ai-security/",
                      "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
                      "https://thehackernews.com/2025/04/meta-launches-llamafirewall-framework.html",
                      "https://www.npr.org/2025/05/31/nx-s1-5407870/meta-ai-facebook-instagram-risks"
                    ],
                    "justification": "Meta demonstrates some security practices including safeguards like Llama Guard and security tools, but there is limited public evidence of systematic software update management and compliance monitoring specifically for AI model weights. The company has shifted to automating 90% of risk assessments with AI, reducing human oversight."
                  }
                }
              }
            ]
          },
          {
            "name": "Access, Permissions, and Credentials",
            "controls": [
              {
                "name": "Least privilege principle",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI demonstrates strong implementation of least privilege principle through multi-party approval requirements for model weight access, role-based access control (RBAC) via Azure Entra ID, and their AccessManager Service that enables least-privilege authorization for sensitive resources including model weights."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/transparency/voluntary-commitments",
                      "https://www.anthropic.com/rsp-updates",
                      "https://privacy.anthropic.com/en/articles/10458704-how-does-anthropic-protect-the-personal-data-of-claude-ai-users",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "Anthropic has implemented two-party authorization for model weight access, grants only temporary access with smallest necessary permissions, and requires hardware authentication and justification for access - demonstrating strong adherence to least privilege principle."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/vertex-ai/docs/general/access-control",
                      "https://cloud.google.com/architecture/framework/perspectives/ai-ml/security",
                      "https://cloud.google.com/vertex-ai/generative-ai/docs/control-model-access",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html"
                    ],
                    "justification": "Google demonstrates partial implementation of least privilege for AI model weights through IAM access controls in Vertex AI and emphasizes secure-by-default infrastructure. However, public documentation lacks specific details about restricting AI model weights access, which is a critical component of Security Level 1 as described in the RAND report."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://krebsonsecurity.com/2025/05/xai-dev-leaks-api-key-for-private-spacex-tesla-llms/"
                    ],
                    "justification": "While xAI experienced a significant API key leak exposing access to 60+ private LLMs for 2 months (indicating poor access control practices), there is insufficient public information about their systematic implementation of least privilege principles for model weights security to provide a comprehensive assessment."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of least privilege principle for AI model weights security as described in the RAND report's Security Level 1 requirements."
                  }
                }
              },
              {
                "name": "Restrictions on device and account sharing",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://openai.com/policies/terms-of-use",
                      "https://openai.com/policies/services-agreement/"
                    ],
                    "justification": "OpenAI has documented policies prohibiting account sharing and unauthorized access, but lacks publicly available information on specific technical controls for device restrictions related to model weights security."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy"
                    ],
                    "justification": "Anthropic has implemented ASL-3 security controls including two-party authorization for model weight access, multi-party authorization with time-bounded access controls, and access management with multiple clearance levels and granular per-role permissions, demonstrating strong restrictions on device and account sharing."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Google's implementation of device and account sharing restrictions for AI model weights security as described in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/legal/terms-of-service",
                      "https://en.wikipedia.org/wiki/Grok_(chatbot)",
                      "https://github.com/xai-org/grok-1/discussions/246",
                      "https://x.ai/legal/privacy-policy"
                    ],
                    "justification": "xAI shows minimal compliance with device and account sharing restrictions for model weights. While they have basic account security measures (password protection, limiting devices for mobile apps), they openly released Grok-1 model weights under Apache 2.0 license and plan to open-source Grok-2, indicating limited restrictions on model weights sharing."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of device and account sharing restrictions for AI model weights security as defined in RAND's Security Level 1. While Meta has various privacy controls for user data and AI services, there is no publicly available information addressing their compliance with this specific security control for protecting AI model weights."
                  }
                }
              },
              {
                "name": "Password best practices",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found addressing OpenAI's password practices for AI model weights security as described in RAND's Security Level 1."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/voluntary-commitments",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "Anthropic has implemented two-party authorization/control for model weight access and multi-factor authentication, demonstrating strong authentication practices. However, specific details about comprehensive password policies (complexity, rotation, storage) are not publicly disclosed."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Google's implementation of password best practices for AI model weights security as defined in RAND Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html"
                    ],
                    "justification": "xAI states they adhere to NIST SP 800-63B password security standards on their security page, but no specific public information addresses password practices for AI model weight security as outlined in the RAND report's Security Level 1."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found directly addressing Meta's password best practices for AI model weights security as outlined in the RAND report's Security Level 1 requirements."
                  }
                }
              },
              {
                "name": "Multifactor authentication",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://help.openai.com/en/articles/7967234-enabling-multi-factor-authentication-mfa-with-openai",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html"
                    ],
                    "justification": "OpenAI has implemented MFA for user accounts accessing their services, and their published security architecture mentions multi-party approvals for accessing model weights. However, there is no specific public information confirming comprehensive MFA implementation for all personnel accessing AI model weights as required by RAND's Security Level 1."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/transparency/voluntary-commitments"
                    ],
                    "justification": "Anthropic has publicly disclosed implementation of multifactor authentication as part of their model weights security controls, specifically mentioning 'two-party controls, with explicit per-user access validation and multifactor authentication' and requiring 'hardware authentication device prompt' for access to model weights under their ASL-3 security standards."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found addressing Google's implementation of multifactor authentication for AI model weights security as described in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html"
                    ],
                    "justification": "xAI publicly states they use hardware-based MFA (USB security keys) for system access, but there's no specific public information confirming this extends to AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of multifactor authentication for AI model weights security."
                  }
                }
              },
              {
                "name": "Single Sign-On (SSO)",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI implements enterprise-level authentication through SAML SSO for ChatGPT Enterprise and API platforms, and employs multi-party approvals and authentication requirements for accessing model weights storage, demonstrating strong SSO controls for model weights security."
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found directly addressing Anthropic's use of SSO for AI model weights security as described in the RAND report's Security Level 1."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Google's implementation of SSO for AI model weights security as required by Security Level 1 in the RAND report."
                  },
                  "xAI": {
                    "score": 75,
                    "sources": [
                      "https://x.ai/security"
                    ],
                    "justification": "xAI explicitly states they use SSO for internal applications with WebAuthn and hardware-based MFA, and support SAML-based SSO for Business Tier accounts, demonstrating a strong SSO implementation aligned with security best practices."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of Single Sign-On (SSO) for AI model weights security as described in RAND's Security Level 1."
                  }
                }
              },
              {
                "name": "Backup and recovery tools",
                "compliance": {
                  "OpenAI": {
                    "score": 25,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has published information about security architecture for model weights protection including defense-in-depth approaches and multi-layered controls, but specific details about backup and recovery tools implementation are not publicly disclosed."
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Anthropic's backup and recovery tools for AI model weights, despite extensive documentation of other security controls."
                  },
                  "Google": {
                    "score": 25,
                    "sources": [
                      "https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html"
                    ],
                    "justification": "Google provides general backup and recovery capabilities for AI/ML workloads through Cloud Storage and checkpointing mechanisms, but no specific public information addresses backup and recovery tools explicitly designed for AI model weights security as outlined in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security"
                    ],
                    "justification": "xAI documents general backup procedures including daily database snapshots and semi-annual restoration testing, but lacks specific public information about backup and recovery tools for AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of backup and recovery tools for AI model weights security."
                  }
                }
              },
              {
                "name": "Commercial identity and access management (IAM) tools",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://www.forrester.com/blogs/openai-requires-identity-verification-for-access-to-its-latest-models/",
                      "https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/role-based-access-control",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has implemented robust IAM controls including Azure Entra ID integration, role-based access control, multi-party approval requirements for sensitive resources, and AccessManager Service for least-privilege authorization. The company recently introduced mandatory identity verification for accessing advanced models and employs defense-in-depth approaches specifically for protecting model weights."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/enterprise",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://support.anthropic.com/en/articles/9797544-setting-up-single-sign-on-on-the-enterprise-plan"
                    ],
                    "justification": "Anthropic has implemented enterprise-grade IAM features including SSO, SAML, SCIM, domain capture, role-based permissions, and two-party authorization for model weight access as part of their ASL-3 security controls, demonstrating strong adoption of commercial IAM tools for securing AI model weights."
                  },
                  "Google": {
                    "score": 75,
                    "sources": [
                      "https://cloud.google.com/architecture/framework/perspectives/ai-ml/security",
                      "https://cloud.google.com/security/products/iam",
                      "https://cloud.google.com/blog/products/identity-security/mastering-secure-ai-on-google-cloud-a-practical-guide-for-enterprises"
                    ],
                    "justification": "Google Cloud provides comprehensive commercial IAM tools with fine-grained access control, audit trails, and role-based permissions management. While not explicitly documented for AI model weights protection at RAND's Security Level 1, Google's IAM system offers the capabilities needed for basic access control and monitoring required at this level."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI's security page explicitly mentions using Amazon IAM for access control and following least privilege principles, but lacks specific details about commercial IAM tools for model weights security as described in RAND's Security Level 1."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of commercial IAM tools for AI model weights security. While Meta has security frameworks like LlamaFirewall and discusses security best practices in cloud deployments, there is no direct evidence of commercial IAM tool usage for model weights protection."
                  }
                }
              },
              {
                "name": "Zero Trust architecture (adherence to at least the standards in the \"Traditional\" level of CISA's Zero Trust Maturity Model)",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI demonstrates strong implementation of Zero Trust principles including multi-party approval requirements for sensitive access, defense-in-depth architecture with multiple security layers, least-privilege authorization through AccessManager Service, and continuous verification through authentication and authorization controls. Their published security architecture aligns well with traditional-level Zero Trust maturity requirements."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "Anthropic has implemented multi-party authorization controls, two-party control systems, and over 100 security controls for model weight protection under their ASL-3 standards. They follow NIST SSDF and SLSA frameworks and have implemented enhanced access controls with compartmentalization, though specific CISA Zero Trust Maturity Model compliance details are not publicly documented."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://workspace.google.com/security/zero-trust/",
                      "https://cloud.google.com/learn/what-is-zero-trust",
                      "https://workspace.google.com/blog/identity-and-security/accelerating-zero-trust-and-digital-sovereignty-ai",
                      "https://cloud.google.com/beyondcorp"
                    ],
                    "justification": "Google has implemented Zero Trust principles through BeyondCorp and demonstrates compliance with CISA's Zero Trust Maturity Model for general infrastructure and Google Workspace. However, no specific public information was found directly addressing Zero Trust implementation for AI model weights security as described in the RAND report."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about xAI implementing Zero Trust architecture or adhering to CISA's Zero Trust Maturity Model standards for AI model weights security."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://the-ai-alliance.github.io/trust-safety-user-guide/exploring/meta-trust-safety/",
                      "https://www.oligo.security/blog/cve-2024-50050-critical-vulnerability-in-meta-llama-llama-stack",
                      "https://github.com/meta-llama/llama-models"
                    ],
                    "justification": "Meta demonstrates some security practices like trust and safety initiatives and vulnerability patches, but there is no public evidence of comprehensive Zero Trust architecture implementation specifically for AI model weights that meets CISA's Traditional level requirements."
                  }
                }
              }
            ]
          },
          {
            "name": "Hardware",
            "controls": [
              {
                "name": "Modern device architectures that establish root of trust and block malicious code execution",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://openai.com/index/reimagining-secure-infrastructure-for-advanced-ai/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has publicly proposed trusted computing for AI accelerators (GPUs) to encrypt model weights until execution and uses Azure-based infrastructure with defense-in-depth security controls. However, there's no public evidence of full implementation of hardware-based root of trust architectures or TEEs specifically for model weights protection."
                  },
                  "Anthropic": {
                    "score": 25,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/research/confidential-inference-trusted-vms"
                    ],
                    "justification": "Anthropic has implemented binary authorization and endpoint controls that prevent unauthorized code execution, but lacks specific public information confirming implementation of hardware-based root of trust architectures as expected for Security Level 1."
                  },
                  "Google": {
                    "score": 25,
                    "sources": [
                      "https://cloud.google.com/security/securing-ai",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/",
                      "https://cloud.google.com/docs/security/titanium-hardware-security-architecture"
                    ],
                    "justification": "Google has implemented strong hardware root of trust through Titan chips and Caliptra RTM in their infrastructure, but there's no specific public information confirming these are applied to protect AI model weights. Their SAIF framework addresses AI security broadly but doesn't explicitly detail hardware-based protections for model weights."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/news/grok-os",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI mentions using 'trusted hardware' and American-made servers from Dell and HPE to minimize supply chain attacks, but lacks public documentation of specific root of trust implementations or hardware-based security measures for protecting AI model weights."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found confirming Meta's implementation of modern device architectures with hardware root of trust for AI model weights security as defined in RAND's Security Level 1."
                  }
                }
              },
              {
                "name": "CPU anti-exploitation features",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about OpenAI's implementation of CPU anti-exploitation features for AI model weights security."
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Anthropic's implementation of CPU anti-exploitation features for AI model weights security."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Google implementing CPU anti-exploitation features specifically for AI model weights security as described in the RAND report's Security Level 1 requirements."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's compliance with CPU anti-exploitation features for AI model weights security as described in the RAND report."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://engineering.fb.com/2025/04/29/security/whatsapp-private-processing-ai-tools/",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html"
                    ],
                    "justification": "Meta demonstrates limited public disclosure of CPU anti-exploitation features for AI model weights. While they've implemented TEE-based Private Processing for WhatsApp using confidential computing, there's no specific evidence of comprehensive CPU anti-exploitation measures for their broader AI model weights security."
                  }
                }
              }
            ]
          },
          {
            "name": "Supply Chain",
            "controls": [
              {
                "name": "The reputability of software is reviewed before incorporation.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found addressing OpenAI's practices for reviewing software reputability before incorporation in the context of AI model weights security."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/frontier-model-security",
                      "https://www.anthropic.com/transparency/voluntary-commitments"
                    ],
                    "justification": "Anthropic demonstrates strong software security practices including third-party dependency scanning, vulnerability monitoring, binary authorization for endpoints, and comprehensive software supply chain security measures. They implement NIST SSDF and SLSA frameworks, conduct regular security reviews, and have established controls for software inventory management and approval processes."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://research.google/pubs/securing-the-ai-software-supply-chain/",
                      "https://ai.google/responsibility/safety/",
                      "https://cloud.google.com/software-supply-chain-security/docs/overview"
                    ],
                    "justification": "Google demonstrates partial compliance through its SAIF framework emphasizing software supply chain security for AI, Assured Open Source Software program for verified packages, and guidance on securing AI supply chains. However, no specific public information confirms systematic reputability reviews of all software before incorporation in AI model weights security contexts."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about xAI's practices for reviewing the reputability of software before incorporation related to AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's practices for reviewing software reputability before incorporation in the context of AI model weights security."
                  }
                }
              }
            ]
          },
          {
            "name": "Security Tooling",
            "controls": [
              {
                "name": "Modern authentication infrastructure",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has implemented Azure Entra ID for identity management, role-based access control, multi-party approvals for access grants, and authentication requirements for private-linked storage resources containing model weights, demonstrating strong authentication infrastructure aligned with Security Level 1 requirements."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "Anthropic has implemented modern authentication infrastructure including two-party authorization for model weight access, multi-factor authentication, and time-bounded access controls as part of their ASL-3 security measures, demonstrating strong alignment with Security Level 1 requirements."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://cloud.google.com/blog/products/identity-security/mandatory-mfa-is-coming-to-google-cloud-heres-what-you-need-to-know",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/docs/authentication/mfa-requirement"
                    ],
                    "justification": "Google has announced mandatory MFA for Google Cloud by 2025 and has general security frameworks (SAIF), but no specific public documentation exists detailing modern authentication infrastructure explicitly for AI model weights protection."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://siliconangle.com/2024/03/17/elon-musks-xai-releases-grok-1-architecture-apple-advances-multimodal-ai-research/",
                      "https://x.ai/news/grok-os",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI publicly states adherence to NIST SP 800-63B authentication standards on their security page, but lacks specific public documentation about modern authentication infrastructure for AI model weights security as expected for RAND Security Level 1."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Meta's modern authentication infrastructure implementation for AI model weights security as described in RAND's Security Level 1."
                  }
                }
              },
              {
                "name": "Commercial network security solutions",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy",
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk"
                    ],
                    "justification": "OpenAI has implemented several commercial network security solutions including SOC 2 Type 2 certification, network isolation, TLS 1.2+ encryption, access controls, and dedicated Azure-based infrastructure with Kubernetes orchestration. These measures align well with RAND Security Level 1 requirements for protecting against amateur attempts and basic attacks."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/frontier-model-security",
                      "https://venturebeat.com/ai/why-anthropic-and-openai-are-obsessed-with-securing-llm-model-weights/"
                    ],
                    "justification": "Anthropic has implemented over 100 security controls including egress bandwidth controls, two-party authorization for model weight access, enhanced change management protocols, and endpoint software controls, demonstrating strong commercial security measures aligned with industry best practices for protecting AI model weights."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Google's implementation of commercial network security solutions for AI model weights security as described in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's implementation of commercial network security solutions for AI model weights protection as expected for Security Level 1 in the RAND report."
                  },
                  "Meta": {
                    "score": 50,
                    "sources": [
                      "https://about.fb.com/news/2024/11/open-source-ai-america-global-security/",
                      "https://www.infosecurity-magazine.com/news/meta-new-advances-ai-security/",
                      "https://venturebeat.com/ai/rsac-2025-cisco-and-meta-put-open-source-ai-at-the-heart-of-enterprise-threat-defense/"
                    ],
                    "justification": "Meta demonstrates partial compliance through partnerships with AWS and Microsoft Azure for secure cloud hosting of Llama models, and development of security tools like LlamaFirewall and Llama Guard. However, no specific evidence found of comprehensive commercial network security solutions implementation as detailed in RAND's Security Level 1 requirements."
                  }
                }
              },
              {
                "name": "Commercial endpoint security solutions",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI has publicly disclosed implementing several security measures including data encryption (AES-256 at rest, TLS 1.2+ in transit), access controls, SOC 2 compliance, and identity management systems. However, specific details about commercial endpoint security solutions deployment for model weights protection are not publicly disclosed."
                  },
                  "Anthropic": {
                    "score": 50,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "Anthropic has implemented ASL-3 security measures including enhanced internal security controls and egress bandwidth monitoring, but no specific public information confirms deployment of commercial endpoint security solutions as described in the RAND report for Security Level 1."
                  },
                  "Google": {
                    "score": 25,
                    "sources": [
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/blog/products/identity-security/introducing-ai-protection-security-for-the-ai-era",
                      "https://cloud.google.com/endpoint-verification/docs/overview",
                      "https://cloud.google.com/security/securing-ai",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html"
                    ],
                    "justification": "Google discusses AI security broadly through SAIF framework and Model Armor, but lacks specific public documentation about implementing commercial endpoint security solutions (EDR/EPP) for protecting AI model weights infrastructure as outlined in RAND's Security Level 1 requirements."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI mentions having endpoint security measures and device management tools, but publicly available information does not specifically address commercial endpoint security solutions for AI model weights protection as per RAND's framework."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Meta implementing commercial endpoint security solutions for AI model weights protection as described in RAND's Security Level 1."
                  }
                }
              },
              {
                "name": "Reliance on standard security infrastructure (depending on circumstances)",
                "compliance": {
                  "OpenAI": {
                    "score": 75,
                    "sources": [
                      "https://learn.microsoft.com/en-us/security/benchmark/azure/baselines/azure-openai-security-baseline",
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI demonstrates strong reliance on standard security infrastructure including Azure cloud services, Kubernetes orchestration, Azure Entra ID for identity management, role-based access control, TLS encryption, private endpoints, and defense-in-depth approaches. However, they acknowledge that securing against the most capable actors requires more investment."
                  },
                  "Anthropic": {
                    "score": 100,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/news/frontier-model-security",
                      "https://www.maginative.com/article/anthropic-calls-for-stringent-security-safeguards-for-frontier-ai-models/"
                    ],
                    "justification": "Anthropic has implemented ASL-2 and ASL-3 security standards with over 100 security controls, including two-party authorization, endpoint controls, and cybersecurity best practices, significantly exceeding basic Security Level 1 requirements."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found addressing Google's compliance with RAND Security Level 1 requirements for AI model weights security."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://www.oracle.com/news/announcement/xais-grok-models-are-now-on-oracle-cloud-infrastructure-2025-06-17/",
                      "https://job-boards.greenhouse.io/xai/jobs/4559149007",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI's security page shows basic infrastructure security measures (VPN access, encryption, cloud security tools), but lacks specific public documentation about AI model weights security controls as outlined in RAND's Security Level 1 requirements."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of standard security infrastructure for AI model weights protection as outlined in RAND's Security Level 1 requirements."
                  }
                }
              }
            ]
          },
          {
            "name": "Configuration Management",
            "controls": [
              {
                "name": "Enforce screen locks for inactivity",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding OpenAI's enforcement of screen locks for inactivity as related to AI model weights security."
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Anthropic's implementation of screen locks for inactivity as a security control for AI model weights protection."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Google's implementation of screen lock for inactivity policies related to AI model weights security."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's implementation of screen lock enforcement for inactivity as it relates to AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's implementation of screen locks for inactivity as a security control for AI model weights."
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Personnel Security",
        "subcategories": [
          {
            "name": "Awareness and Training",
            "controls": [
              {
                "name": "Basic onboarding information security training for employees",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about OpenAI's basic onboarding information security training for employees related to AI model weights security."
                  },
                  "Anthropic": {
                    "score": 25,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/news/frontier-model-security"
                    ],
                    "justification": "While Anthropic emphasizes security culture and has an insider threat program with employee education, no specific details about basic onboarding security training were found in public documentation. The company mentions educating employees on insider risk but lacks public disclosure of comprehensive onboarding security training programs."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://workspace.google.com/solutions/ai/",
                      "https://workspace.google.com/learn-more/security/security-whitepaper/page-2/",
                      "https://ai.google/learn-ai-skills/"
                    ],
                    "justification": "Google has comprehensive security training for all employees including onboarding programs and ongoing security education, but no specific public information was found about training explicitly focused on AI model weights security as outlined in the RAND report's Security Level 1 requirements."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's implementation of basic onboarding information security training for employees related to AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found addressing Meta's basic onboarding information security training for employees related to AI model weights security."
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security Assurance and Testing",
        "subcategories": [
          {
            "name": "Risk and Security Assessments",
            "controls": [
              {
                "name": "Internal reviews",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding OpenAI's implementation of 'internal reviews' as a security control for AI model weights as described in RAND's Security Level 1."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates"
                    ],
                    "justification": "Anthropic has implemented multi-party authorization for model weight access, mandatory code review on production code, and requires hardware authentication, justification, and employee approval for access. The company also established an Executive Risk Council for oversight and conducts routine safeguard assessments."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://deepmind.google/about/responsibility-safety/",
                      "https://ai.google/responsibility/safety/",
                      "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/"
                    ],
                    "justification": "Google has established internal review processes through its Responsibility and Safety Council (RSC) and AGI Safety Council that evaluate AI research and models, and has published security guidance, but lacks specific public documentation detailing internal review procedures focused on model weights security as outlined in the RAND report."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about xAI's internal review practices for AI model weights security. While xAI has published general security measures and signed safety commitments, there is no publicly available documentation addressing internal reviews specifically related to model weights protection."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's internal review processes for AI model weights security as defined in the RAND report's Security Level 1 requirements."
                  }
                }
              }
            ]
          },
          {
            "name": "Security Team Capacity",
            "controls": [
              {
                "name": "Basic incident response capabilities",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://openai.com/security/",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk",
                      "https://trust.openai.com/"
                    ],
                    "justification": "OpenAI demonstrates some incident response capabilities through their Trust Portal incident response plan, SOC 2 Type 2 compliance, bug bounty program, and documented security incident handling procedures. However, public information lacks specific details about incident response capabilities focused on AI model weights security as outlined in the RAND framework."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates"
                    ],
                    "justification": "Anthropic has implemented comprehensive incident response capabilities including centralized log management via SIEM/SOAR, automated detection and response workflows, casebook workflow for security analysts, access monitoring for model weights with automated detections, and enhanced detection capabilities through egress bandwidth controls and deception technology with honeypots."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found about Google's incident response capabilities for AI model weights security as defined in RAND's Security Level 1."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/security",
                      "https://ubos.tech/news/xais-grok-incident-highlights-the-importance-of-ai-security-and-content-moderation/"
                    ],
                    "justification": "xAI has published formal incident management framework, 24/7 monitoring, and vulnerability disclosure program, but no specific public documentation found addressing model weights security incident response."
                  },
                  "Meta": {
                    "score": 50,
                    "sources": [
                      "https://www.tryparity.com/blog/how-meta-uses-llms-to-improve-incident-response",
                      "https://rootly.com/blog/how-meta-and-google-use-ai-to-improve-incident-response",
                      "https://www.securityweek.com/meta-releases-llama-ai-open-source-protection-tools/",
                      "https://www.artificialintelligence-news.com/news/meta-beefs-up-ai-security-new-llama-tools/",
                      "https://www.infosecurity-magazine.com/news/meta-new-advances-ai-security/"
                    ],
                    "justification": "Meta demonstrates incident response capabilities for AI systems with 42% accuracy in root cause analysis using LLMs, and has released security tools like Llama Guard 4 and LlamaFirewall. However, no specific public information was found detailing incident response procedures for AI model weights security breaches."
                  }
                }
              }
            ]
          },
          {
            "name": "Maintenance",
            "controls": [
              {
                "name": "Information security news monitoring and implementation",
                "compliance": {
                  "OpenAI": {
                    "score": 25,
                    "sources": [
                      "https://www.analyticsvidhya.com/blog/2024/05/openai-security-measures/",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://www.fierce-network.com/cloud/model-weights-are-heart-ais-intelligence-and-its-achilles-heel"
                    ],
                    "justification": "OpenAI has publicly acknowledged model weight security as critical and proposed comprehensive security measures, but no specific public evidence was found demonstrating implementation of information security news monitoring systems specifically for AI model weights as outlined in RAND's Security Level 1."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/transparency/voluntary-commitments"
                    ],
                    "justification": "Anthropic demonstrates strong security monitoring through threat intelligence partnerships, bug bounty programs, regular threat modeling considering nation-state actors, and rapid response processes for sharing threat intelligence with partners. They've implemented ASL-3 security controls with over 100 security measures specifically for model weight protection."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/blog/products/identity-security/introducing-ai-protection-security-for-the-ai-era",
                      "https://safety.google/cybersecurity-advancements/saif/",
                      "https://cloud.google.com/vertex-ai/docs/model-monitoring/overview",
                      "https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/"
                    ],
                    "justification": "Google has demonstrated security monitoring capabilities through Vertex AI Model Monitoring and their Secure AI Framework (SAIF), but no specific public evidence shows implementation of continuous security news monitoring specifically for AI model weights threats as described in RAND's Security Level 1 requirements."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's implementation of information security news monitoring and implementation related to AI model weights security as described in the RAND report."
                  },
                  "Meta": {
                    "score": 50,
                    "sources": [
                      "https://www.securityweek.com/meta-releases-llama-ai-open-source-protection-tools/",
                      "https://www.infosecurity-magazine.com/news/meta-new-advances-ai-security/",
                      "https://thehackernews.com/2025/01/metas-llama-framework-flaw-exposes-ai.html",
                      "https://www.unite.ai/from-jailbreaks-to-injections-how-meta-is-strengthening-ai-security-with-llama-firewall/"
                    ],
                    "justification": "Meta has implemented some security monitoring tools for AI (Llama Guard, LlamaFirewall, Prompt Guard) and released security updates, but lacks specific public documentation about comprehensive information security news monitoring systems for AI model weights threats as outlined in the RAND report's Security Level 1 requirements."
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "level": 2,
    "description": "A system that can likely thwart most professional opportunistic efforts by attackers that execute moderate-effort or nontargeted attacks (OC2). This includes the operations of many professional individual hackers, as well as capable hacker groups when executing untargeted or lower-priority attacks.",
    "categories": [
      {
        "name": "Implementation of Previous Security Levels",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "The organization has implemented all the controls from SL1.",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://openai.com/security/",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://openai.com/global-affairs/our-approach-to-frontier-risk"
                    ],
                    "justification": "OpenAI demonstrates implementation of basic security controls including encryption, access controls, SOC 2 compliance, and 24/7 security operations, but lacks public documentation specifically addressing all SL1 controls from the RAND framework."
                  },
                  "Anthropic": {
                    "score": 50,
                    "sources": [
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.rand.org/news/press/2024/05/30.html"
                    ],
                    "justification": "Anthropic has implemented ASL-2 security measures which include 'defenses against opportunistic attempts to steal the weights' and recently upgraded to ASL-3 with over 100 security controls. However, the RAND report indicates that Security Level 1 measures are not widely implemented across the industry, and Anthropic's ASL-2 baseline appears to align more with Security Level 2 (protecting against opportunistic attacks) rather than fully implementing all SL1 controls."
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Google's implementation of RAND's Security Level 1 controls for AI model weights security. While Google discusses security measures for Gemini models, there is no evidence they have adopted or implemented the specific SL1 controls framework from the RAND report."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [
                      "https://techcrunch.com/2025/05/13/xais-promised-safety-report-is-mia/",
                      "https://www.rand.org/pubs/research_reports/RRA2849-1.html",
                      "https://x.ai/security"
                    ],
                    "justification": "No specific public information found detailing xAI's implementation of RAND SL1 controls for AI model weights security. While xAI has published general security information, there is no evidence of compliance with the specific controls required by SL1."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://thehackernews.com/2025/01/metas-llama-framework-flaw-exposes-ai.html",
                      "https://www.oligo.security/blog/cve-2024-50050-critical-vulnerability-in-meta-llama-llama-stack",
                      "https://www.edgeless.systems/solutions/ai-model-protection",
                      "https://www.nextplatform.com/2024/07/25/meta-lets-its-largest-llama-ai-model-loose-into-the-open-field/",
                      "https://www.infosecurity-magazine.com/news/meta-new-advances-ai-security/"
                    ],
                    "justification": "While Meta has implemented some security controls like Llama Guard and LlamaFirewall, public evidence of a model weights leak and recent security vulnerabilities indicate incomplete implementation of SL1's comprehensive security measures, particularly around weight centralization and access control."
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Weight Security",
        "subcategories": [
          {
            "name": "Weight Storage",
            "controls": [
              {
                "name": "Storage location (e.g., weights are stored exclusively on servers and not on local devices)",
                "compliance": {
                  "OpenAI": {
                    "score": 100,
                    "sources": [
                      "https://openai.com/enterprise-privacy",
                      "https://openai.com/index/openai-api/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI stores model weights exclusively on servers through their API-based approach, with multi-layered security controls including private-linked storage requiring authentication/authorization, and does not release model weights for local device storage."
                  },
                  "Anthropic": {
                    "score": 50,
                    "sources": [
                      "https://privacy.anthropic.com/en/articles/7996890-where-are-your-servers-located-do-you-host-your-models-on-eu-servers",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://venturebeat.com/ai/why-anthropic-and-openai-are-obsessed-with-securing-llm-model-weights/"
                    ],
                    "justification": "Anthropic implements egress bandwidth controls for secure computing environments where model weights reside and uses cloud providers for data processing, suggesting server-based storage, but no explicit public statement confirms weights are stored exclusively on servers and never on local devices."
                  },
                  "Google": {
                    "score": 25,
                    "sources": [
                      "https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml",
                      "https://cloud.google.com/blog/products/application-development/new-localllm-lets-you-develop-gen-ai-apps-locally-without-gpus",
                      "https://developer.chrome.com/docs/ai/built-in",
                      "https://research.google/blog/unlocking-7b-language-models-in-your-browser-a-deep-dive-with-google-ai-edges-mediapipe/",
                      "https://techcrunch.com/2025/05/31/google-quietly-released-an-app-that-lets-you-download-and-run-ai-models-locally/"
                    ],
                    "justification": "Google has released apps allowing local model execution (AI Edge Gallery) and promotes on-device AI capabilities, indicating weights are not stored exclusively on servers. However, Google Cloud's infrastructure emphasizes secure server-based storage for enterprise AI workloads."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [
                      "https://www.oracle.com/artificial-intelligence/ai-open-weights-models/",
                      "https://x.ai/news/grok-os",
                      "https://blocksandfiles.com/2024/11/19/ddn-supplying-storage-for-xais-grok-3-colossus-ai-supercomputer/",
                      "https://github.com/xai-org/grok-1/discussions/246"
                    ],
                    "justification": "No specific public information found regarding xAI's policies on exclusive server storage vs. local device storage of model weights. While xAI operates the Colossus supercomputer for training and has open-sourced Grok-1 weights, their security practices for weight storage location are not publicly documented."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found directly addressing whether Meta stores AI model weights exclusively on servers versus local devices."
                  }
                }
              },
              {
                "name": "Encryption (e.g., all keys are secured in a key management system)",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://learn.microsoft.com/en-us/azure/ai-services/openai/encrypt-data-at-rest",
                      "https://openai.com/enterprise-privacy",
                      "https://siliconangle.com/2024/04/23/openai-enhances-security-control-cost-management-enterprise-api-users/",
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065"
                    ],
                    "justification": "OpenAI implements AES-256 encryption for data at rest and TLS 1.2+ for data in transit, and uses key management services for sensitive information. However, no specific public information confirms that all model weight encryption keys are secured in a dedicated key management system as required for Security Level 2."
                  },
                  "Anthropic": {
                    "score": 75,
                    "sources": [
                      "https://privacy.anthropic.com/en/articles/10458704-how-does-anthropic-protect-the-personal-data-of-claude-ai-users",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/research/confidential-inference-trusted-vms"
                    ],
                    "justification": "Anthropic has implemented ASL-3 security standards including two-party authorization for model weight access, encryption of data in transit and at rest, and preliminary egress bandwidth controls specifically designed to protect model weights. However, no explicit mention of a dedicated key management system (KMS) for model weight encryption keys was found."
                  },
                  "Google": {
                    "score": 50,
                    "sources": [
                      "https://cloud.google.com/kms/docs",
                      "https://cloud.google.com/vertex-ai/docs/general/cmek",
                      "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/"
                    ],
                    "justification": "Google demonstrates strong general encryption practices with Cloud KMS supporting CMEK for various AI services including Vertex AI, but lacks specific public documentation explicitly addressing encryption and key management for AI model weights as a distinct security concern."
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding xAI's encryption practices or key management systems for AI model weights security."
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": "No specific public information found regarding Meta's encryption practices or key management systems for AI model weights security."
                  }
                }
              }
            ]
          },
          {
            "name": "Security During Transport and Use",
            "controls": [
              {
                "name": "Encryption in transit (e.g., not transporting weights over public or unencrypted channels)",
                "compliance": {
                  "OpenAI": {
                    "score": 50,
                    "sources": [
                      "https://web.swipeinsight.app/posts/openai-unveils-security-architecture-for-frontier-ai-model-training-7065",
                      "https://openai.com/enterprise-privacy",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html"
                    ],
                    "justification": "OpenAI states they encrypt all data in transit using TLS 1.2+, but there is no specific public information about security measures for model weights during transport, which the RAND report identifies as a critical security gap."
                  },
                  "Anthropic": {
                    "score": 50,
                    "sources": [
                      "https://privacy.anthropic.com/en/articles/10458704-how-does-anthropic-protect-the-personal-data-of-claude-ai-users",
                      "https://www.anthropic.com/news/activating-asl3-protections",
                      "https://www.anthropic.com/rsp-updates",
                      "https://www.anthropic.com/research/confidential-inference-trusted-vms"
                    ],
                    "justification": "Anthropic has implemented ASL-3 security standards with over 100 security controls and mentions protecting model weights through encryption and access controls, but no specific public information confirms encryption during transport of weights."
                  },
                  "Google": {
                    "score": 75,
                    "sources": [
                      "https://cloud.google.com/docs/security/encryption-in-transit/application-layer-transport-security",
                      "https://cloud.google.com/docs/security/encryption-in-transit",
                      "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/"
                    ],
                    "justification": "Google implements comprehensive encryption in transit by default across its infrastructure using TLS, ALTS, and PSP protocols. While Google DeepMind's security frameworks emphasize weight protection and mention security mitigations to prevent exfiltration, specific public documentation on encryption during model weight transport is limited."
                  },
                  "xAI": {
                    "score": 25,
                    "sources": [
                      "https://x.ai/news/grok-os",
                      "https://x.ai/security"
                    ],
                    "justification": "xAI's security page mentions TLS encryption for web application and API communications, but does not specifically address encryption protocols for model weight transport. They publicly released Grok-1 weights, suggesting limited focus on weight security controls."
                  },
                  "Meta": {
                    "score": 25,
                    "sources": [
                      "https://engineering.fb.com/2019/05/29/security/service-encryption/",
                      "https://github.com/meta-llama/llama-models",
                      "https://en.wikipedia.org/wiki/Llama_(language_model)",
                      "https://www.rand.org/pubs/research_briefs/RBA2849-1.html",
                      "https://engineering.fb.com/2025/04/29/security/whatsapp-private-processing-ai-tools/"
                    ],
                    "justification": "While Meta demonstrates strong encryption capabilities for general infrastructure and specific AI applications like WhatsApp Private Processing, there is no specific public information about encryption requirements for transporting AI model weights internally or during distribution, with evidence of unencrypted distribution methods being used."
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Data centers are guarded, and only people with authorization are allowed inside.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Visitor access is restricted and logged.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access Control",
            "controls": [
              {
                "name": "Restrictions on sensitive interactions (e.g., require multifactor authentication using FIDO authentication/hardware security keys)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Monitoring",
            "controls": [
              {
                "name": "Logging of all sensitive interactions",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Regulation and monitoring of weight copies across the organization network",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "AI Model Resilience",
        "subcategories": [
          {
            "name": "Model Robustness",
            "controls": [
              {
                "name": "Input reconstruction (e.g., during inference, a privately known prefix is added ahead of the user prompt)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Adversarial training",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security of Network and Other (Nonweight) Sensitive Assets",
        "subcategories": [
          {
            "name": "Software",
            "controls": [
              {
                "name": "Frequent software update management and compliance monitoring",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access, Permissions, and Credentials",
            "controls": [
              {
                "name": "Strong password enforcement",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "The work network is separate from the guest network.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Guest accounts disabled whenever possible",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Strong access management tools",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Zero Trust architecture (adherence to at least the standards in the \"Initial\" level of CISA's Zero Trust Maturity Model)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Hardware",
            "controls": [
              {
                "name": "Lost or stolen devices reported",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "All network devices are visible and trackable.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Supply Chain",
            "controls": [
              {
                "name": "Review of vendor and supplier security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Tooling",
            "controls": [
              {
                "name": "Disk encryption",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Network communications are encrypted by default.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Email security tools",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Use of integrated security approaches, such as eXtended Detection and Response (XDR)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Configuration Management",
            "controls": [
              {
                "name": "Incorporate fundamental infrastructure and policies for Security-by-Design and Security-by-Default",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Configuration management monitoring",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Office security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Careful disposal of printed materials",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Personnel Security",
        "subcategories": [
          {
            "name": "Awareness and Training",
            "controls": [
              {
                "name": "Periodic mandatory information security training for all employees",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Employee training on configuration errors and their security implications",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Filtering and Monitoring",
            "controls": [
              {
                "name": "Installation of monitoring software for secure network access",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Active drills to identify and educate noncompliant employees",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security Assurance and Testing",
        "subcategories": [
          {
            "name": "Red-Teaming and Penetration Testing",
            "controls": [
              {
                "name": "Mandatory external reviews",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Community Involvement and Reporting",
            "controls": [
              {
                "name": "Bug-bounty and vulnerability-discovery programs",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Software Development Process",
            "controls": [
              {
                "name": "Secure software development standards (compliance with NIST's Secure Software Development Framework)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Incident Response",
            "controls": [
              {
                "name": "Protocols and funding for rapid incident response",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Incident reporting",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Team Capacity",
            "controls": [
              {
                "name": "Constant availability of qualified personnel",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Maintenance",
            "controls": [
              {
                "name": "Continuous vulnerability management and adaptation to information security developments",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Other Organization Policies",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "Promotion of a security mindset by organization management",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Stringent remote work policies",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "level": 3,
    "description": "A system that can likely thwart cybercrime syndicates or insider threats (OC3). This includes the operations of many world-renowned criminal hacker groups, well-resourced terrorist organizations, disgruntled employees, and industrial espionage organizations.",
    "categories": [
      {
        "name": "Implementation of Previous Security Levels",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "The organization has implemented all the controls from SL1 and SL2.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Weight Security",
        "subcategories": [
          {
            "name": "Weight Storage",
            "controls": [
              {
                "name": "Centralized and restricted management of weight storage",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Secure cloud network (if applicable)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Dedicated devices for weights and weight security data",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Data centers are guarded or locked at all times.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Premises are swept for intruders frequently (e.g., hourly).",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Premises are meticulously swept for unauthorized devices routinely (e.g., monthly).",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Permitted Interfaces",
            "controls": [
              {
                "name": "Authorized users who interact with the weights do so only through a software interface that reduces risk of the weights being illegitimately copied.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Any code accessing the weights minimizes attack surface, provides only simple forms of access, and uses the minimal amount of (highly trusted and well-established) external code necessary.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Avoiding model interactions that bypass monitoring or constraints",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access Control",
            "controls": [
              {
                "name": "Protocols and policies for sensitive interactions (e.g., access to the various permitted interfaces to the weights is stringently controlled, multiparty authorization, security reviews, etc.)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Monitoring",
            "controls": [
              {
                "name": "Ongoing manual monitoring of sensitive interactions",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Ongoing automated anomaly detection",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Automated and manual monitoring/blocking of potentially malicious queries",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Frequent compromise assessment",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Frequent integrity checks via comparison against a baseline system configuration (\"gold image\")",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Standard Compliance",
            "controls": [
              {
                "name": "Implementation of measures described by NIST SP 800-171 or equivalent",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Future implementation of measures described by CMMC 2.0 Level 3",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "AI Model Resilience",
        "subcategories": [
          {
            "name": "Model Robustness",
            "controls": [
              {
                "name": "Adversarial input detection",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Oracle Protection",
            "controls": [
              {
                "name": "Limitations on the number of inferences using the same credentials",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security of Network and Other (Nonweight) Sensitive Assets",
        "subcategories": [
          {
            "name": "Software",
            "controls": [
              {
                "name": "Very frequent software update management and compliance monitoring",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access, Permissions, and Credentials",
            "controls": [
              {
                "name": "802.1x authentication",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Zero Trust architecture (adherence to at least the standards in the \"Advanced\" level of CISA's Zero Trust Maturity Model)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Hardware",
            "controls": [
              {
                "name": "Security-minded hardware sourcing",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Supply Chain",
            "controls": [
              {
                "name": "Software inventory management",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Supply chain security is commensurate with the organization's security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Tooling",
            "controls": [
              {
                "name": "Enforcement of security policies through code rather than manual compliance",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Security policy enforcement for network access across devices",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Personnel Security",
        "subcategories": [
          {
            "name": "Awareness and Training",
            "controls": [
              {
                "name": "Employee awareness of weight interaction monitoring",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Security training for employees (not necessarily only those with access)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Security risk reporting program",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Filtering and Monitoring",
            "controls": [
              {
                "name": "Insider threat program",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security Assurance and Testing",
        "subcategories": [
          {
            "name": "Red-Teaming and Penetration Testing",
            "controls": [
              {
                "name": "Ongoing penetration testing",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Penetration testing of physical access and facility security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Elite external team",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Substantial funding",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Access to design and code",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Testing insider threats",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Expanded access",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced red-teaming: Attention to the weights and authentication",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Risk and Security Assessments",
            "controls": [
              {
                "name": "Keeping a risk register",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Threat Detection and Response",
            "controls": [
              {
                "name": "Placement of effective honeypots",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Team Capacity",
            "controls": [
              {
                "name": "General increased capacity (compared with SL2)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Concrete experience with APTs",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Leveraging diverse security experience from leading organizations",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Other Organization Policies",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "Two independent security layers",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "level": 4,
    "description": "A system that can likely thwart most standard operations by leading cyber-capable institutions (OC4). This includes the operations of many of the world's leading state-sponsored groups, many intelligence agencies across the world, and the top cyber-capable nations worldwide, which are able to execute such operations more than 100 times a year.",
    "categories": [
      {
        "name": "Implementation of Previous Security Levels",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "The organization has implemented all the controls from SL1\u00e2\u20ac\u201cSL3.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Weight Security",
        "subcategories": [
          {
            "name": "Weight Storage",
            "controls": [
              {
                "name": "Isolation of weight storage",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Weight storage setup is protected against eavesdropping and the simplest of TEMPEST attacks.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Hardware-enforced limits on output rate",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Reduced communication capabilities",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security During Transport and Use",
            "controls": [
              {
                "name": "Confidential computing (when available)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Increased guarding (compared with SL3) via manned and digital systems",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Meticulous logging of all access",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Prohibiting devices near the setup",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Permitted Interfaces",
            "controls": [
              {
                "name": "Specialized hardware for all external interfaces",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Monitoring",
            "controls": [
              {
                "name": "Enforcement of time-buffered review (software limitation)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Protection of the monitoring logs at the hardware level",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Comprehensive anomaly detection and alert system over the monitoring logs",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "AI Model Resilience",
        "subcategories": [
          {
            "name": "Model Robustness",
            "controls": [
              {
                "name": "Adversarial output detection",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Oracle Protection",
            "controls": [
              {
                "name": "Output reconstruction",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security of Network and Other (Nonweight) Sensitive Assets",
        "subcategories": [
          {
            "name": "Software",
            "controls": [
              {
                "name": "Limiting the attack surface (e.g., the limited interaction interfaces of a Chromebook)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access, Permissions, and Credentials",
            "controls": [
              {
                "name": "Enforcement of strong random passwords and keys for enhanced security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Zero Trust architecture (adherence to at least the standards in the \"Optimal\" level of CISA's Zero Trust Maturity Model)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Hardware",
            "controls": [
              {
                "name": "All hardware used on devices must undergo source-code auditing and be validated as secure.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Secure hardware required for access",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Ongoing compromise assessment on all devices with access (server or employee)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Supply Chain",
            "controls": [
              {
                "name": "Strict application allowlisting (especially for sandboxes)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "SLSA Level 3 specification for all software used",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Tooling",
            "controls": [
              {
                "name": "Significant investment in advanced security systems",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Banning of unauthorized devices",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Personnel Security",
        "subcategories": [
          {
            "name": "Filtering and Monitoring",
            "controls": [
              {
                "name": "Preventing third-party access and reporting suspected illegitimate incidents",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced insider threat program",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Occasional employee integrity testing",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security Assurance and Testing",
        "subcategories": [
          {
            "name": "Red-Teaming and Penetration Testing",
            "controls": [
              {
                "name": "Ongoing research and red-teaming to identify potential attack methods on the weight interface(s)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Ensuring physical security through red-teaming",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Experience dealing with intelligence agencies",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Risk and Security Assessments",
            "controls": [
              {
                "name": "Automated weight exfiltration attempts",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Manual weight exfiltration attempts",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Compliance with the FedRAMP High standards for security",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Security Team Capacity",
            "controls": [
              {
                "name": "General increased capacity (compared with SL3)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Greater concrete experience with APTs (compared with SL3)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Zero-day vulnerability discovery capabilities",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "The security team is empowered to not compromise security over other stakeholders.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Other Organization Policies",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "Designating sensitive details of the weight security system",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Vetting of investors and other positions of influence",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Prioritizing leak prevention over other organizational goals",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Four independent security layers",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "level": 5,
    "description": "A system that could plausibly be claimed to thwart most top-priority operations by the top cyber-capable institutions (OC5). This includes the handful of operations prioritized by the world's most capable nation-states.",
    "categories": [
      {
        "name": "Implementation of Previous Security Levels",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "The organization has implemented all the controls from SL1\u00e2\u20ac\u201cSL4.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Weight Security",
        "subcategories": [
          {
            "name": "Weight Storage",
            "controls": [
              {
                "name": "Extreme isolation of weight storage (completely isolated network)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Advanced preventive measures for side-channel attacks (e.g., noise injection, time delays, and other tools)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Formal hardware verification of key components",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Physical Security",
            "controls": [
              {
                "name": "Increased significant guarding (compared with SL4) via multiple armed guards and digital security systems at all times.",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Supervised access for everyone",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Routine rigorous device inspections",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Disabling of most communication at the hardware level",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Permitted Interfaces",
            "controls": [
              {
                "name": "Strict limitation of external connections to the completely isolated network",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Access Control",
            "controls": [
              {
                "name": "Irrecoverable key policy (barring alternative access or key retrieval systems)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Standard Compliance",
            "controls": [
              {
                "name": "Protection equivalent to that required for Top Secret (TS)/Sensitive Compartmented Information (SCI)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "AI Model Resilience",
        "subcategories": [
          {
            "name": "Oracle Protection",
            "controls": [
              {
                "name": "Constant inference time",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security of Network and Other (Nonweight) Sensitive Assets",
        "subcategories": [
          {
            "name": "Supply Chain",
            "controls": [
              {
                "name": "Strong limitations on software providers (e.g., only developed internally or by an extremely reliable source)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              },
              {
                "name": "Strong limitations on hardware providers (e.g., only developed internally or by an extremely reliable source)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Personnel Security",
        "subcategories": [
          {
            "name": "Personal Protection",
            "controls": [
              {
                "name": "Proactive protection of executives and individuals handling sensitive materials",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Security Assurance and Testing",
        "subcategories": [
          {
            "name": "Red-Teaming and Penetration Testing",
            "controls": [
              {
                "name": "Proactive search for crucial vulnerabilities (e.g., zero-days)",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          },
          {
            "name": "Maintenance",
            "controls": [
              {
                "name": "Security is strongly prioritized over availability (e.g., barring connecting external devices to the completely isolated network to debug a critical production issue).",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "name": "Other Organization Policies",
        "subcategories": [
          {
            "name": "",
            "controls": [
              {
                "name": "Eight independent security layers",
                "compliance": {
                  "OpenAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Anthropic": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Google": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "xAI": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  },
                  "Meta": {
                    "score": 0,
                    "sources": [],
                    "justification": ""
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  }
]